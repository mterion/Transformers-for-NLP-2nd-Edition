{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnchLDTW9KiN6xf8tMWdGn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **BLEU**"
      ],
      "metadata": {
        "id": "tW0z0ht1Fvs5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFcg0wrMDYO9",
        "outputId": "226e57db-4e36-4541-ad08-3989da931368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 1.0\n"
          ]
        }
      ],
      "source": [
        "#BLEU : Bilingual Evaluation Understudy Score\n",
        "#Copyright 2020, MIT License BLEU Examples\n",
        "#REF PAPER: Kishore Papineni, et al.,2002,“BLEU: a Method for Automatic Evaluation of Machine Translation“. \n",
        "#                                                https://www.aclweb.org/anthology/P02-1040.pdf\n",
        "#NLTK : Natural Language Toolkit\n",
        "#NLTK sentence_bleu doc: http://www.nltk.org/api/nltk.translate.html#nltk.translate.bleu_score.sentence_bleu\n",
        "#NLTK smoothing doc: https://www.nltk.org/api/nltk.translate.html\n",
        "#NLTK REF PAPER for smoothing():Chen et al.,http://acl2014.org/acl2014/W14-33/pdf/W14-3346.pdf\n",
        "#REF DOC  : https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "\n",
        "#Example 1\n",
        "reference = [['the', 'cat', 'likes', 'milk'], ['cat', 'likes' 'milk']]\n",
        "candidate = ['the', 'cat', 'likes', 'milk']\n",
        "score = sentence_bleu(reference, candidate)\n",
        "print('Example 1', score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example 2\n",
        "reference = [['the', 'cat', 'likes', 'milk']]\n",
        "candidate = ['the', 'cat', 'likes', 'milk']\n",
        "score = sentence_bleu(reference, candidate)\n",
        "print('Example 2', score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDdgiWJLDtBb",
        "outputId": "61dc83c0-542b-42fa-db57-9e678f93c1b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 2 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example 3\n",
        "reference = [['the', 'cat', 'likes', 'milk']]\n",
        "candidate = ['the', 'cat', 'enjoys','milk']\n",
        "score = sentence_bleu(reference, candidate)\n",
        "print('Example 3', score)\n",
        "\n",
        "# A human can see that the score should be 1 and not that low (0.0000000...)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shpt2e4TDgaT",
        "outputId": "ddcea32f-00c6-434d-da17-3edee3b52a26"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 3 1.0547686614863434e-154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chencherry smoothing (improves BLEU techniques)"
      ],
      "metadata": {
        "id": "o5GpKm0sFmme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example 4\n",
        "reference = [['je','vous','invite', 'a', 'vous', 'lever','pour', 'cette', 'minute', 'de', 'silence']]\n",
        "candidate = ['levez','vous','svp','pour', 'cette', 'minute', 'de', 'silence']\n",
        "score = sentence_bleu(reference, candidate)\n",
        "print(\"without soothing score\", score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxBnLAO1D8eu",
        "outputId": "43248166-12c9-409d-b997-b763dbcfe2e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "without soothing score 0.37188004246466494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chencherry = SmoothingFunction()\n",
        "r1=list('je vous invite a vous lever pour cette minute de silence')\n",
        "candidate=list('levez vous svp pour cette minute de silence')\n",
        "        \n",
        "#sentence_bleu([reference1, reference2, reference3], hypothesis2,smoothing_function=chencherry.method1)\n",
        "print(\"with smoothing score\",sentence_bleu([r1], candidate,smoothing_function=chencherry.method1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZLPhw4JFcCZ",
        "outputId": "943600c5-420e-4deb-e62a-311bb7058a68"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with smoothing score 0.6194291765462159\n"
          ]
        }
      ]
    }
  ]
}